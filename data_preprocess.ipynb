{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paste below in your terminal after activating your conda environment\n",
    "# git clone https://github.com/Yichen-Wang-2003/M156_Group1_Final_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/username/M156_Group1_Final_project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "data = datasets.ImageFolder(root='/Users/username/M156_Group1_Final_project/archive/simpsons_dataset', transform=transform)\n",
    "\n",
    "dataloader = DataLoader(data, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "def get_mean_std(loader):\n",
    "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "    \n",
    "    for data, _ in loader:\n",
    "        channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
    "        channels_squared_sum += torch.mean(data**2, dim=[0, 2, 3])\n",
    "        num_batches += 1\n",
    "    \n",
    "    mean = channels_sum / num_batches\n",
    "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
    "    \n",
    "    return mean, std\n",
    "\n",
    "mean, std = get_mean_std(dataloader)\n",
    "\n",
    "print(f'mean: {mean}')\n",
    "print(f'std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation and normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean.tolist(),\n",
    "                         std=std.tolist())\n",
    "])\n",
    "\n",
    "data = datasets.ImageFolder(root='/Users/username/M156_Group1_Final_project/archive/simpsons_dataset', transform=transform)\n",
    "\n",
    "# split the dataset into training and validation\n",
    "train_size = int(0.8 * len(data))\n",
    "val_size = int(0.1 * len(data))\n",
    "test_size = len(data) - train_size - val_size\n",
    "train_data, val_data, test_data = random_split(data, [train_size, val_size, test_size])\n",
    "\n",
    "# create data loaders for training, validation, and testing\n",
    "train = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'found {len(train_data)} images belonging to {len(data.classes)} classes in the training set.')\n",
    "print(f'found {len(val_data)} images belonging to {len(data.classes)} classes in the validation set.')\n",
    "print(f'found {len(test_data)} images belonging to {len(data.classes)} classes in the validation set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pic16B",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
